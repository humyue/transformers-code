{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本分类实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'review'],\n",
       "    num_rows: 7765\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"./ChnSentiCorp_htl_all.csv\", split=\"train\")\n",
    "dataset = dataset.filter(lambda x: x[\"review\"] is not None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 创建DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 6988\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 777\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = dataset.train_test_split(test_size=0.1)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6988, 777)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets[\"train\"]),len(datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 0, 'review': '我是四月初去的深圳。我订的是豪华套房，开始在网上开酒店新装修后的照片挺吸引的，但入住后才发现根本不是那样的。除了大塘有装修过的感觉外，楼层和房间都还是老样子，很旧，完全没有装修过。八百多的房费简直就是浪费，下次不会在住了。'} {'label': 1, 'review': '位置比较好，到机场火车站都很方便。豪华单人间里的布置合理有序，独具匠心。值得一提的是门口迎宾员特别热情，帮我提箱子一直到办完入住还送我上了电梯。'}\n",
      "{'label': 1, 'review': '交通相当便利，既是优点也是缺点，住在十几楼还是有点吵。其它的都还可以吧，四星级嘛。'} {'label': 0, 'review': '特价房环境非常不好，只有一扇非常小的气窗通向宾馆过道，有点象住在地下室的感觉。房间下水道还往上翻难闻的臭气。请慎重选择此宾馆。'}\n",
      "{'label': 0, 'review': '2/17除夕夜订房预订240标间感觉不错!所以2/25再次入住提升为豪标270元,没想到...房间竟比前一次的标间还要小,淋浴间更小到无法转身,连梳妆台,衣橱也都全消失没有了,向前台反应,怎跟前次住的房型还要糟糕~服务员回应不仅态度恶劣,更以前次入住的房间门锁坏了的理由不给转房~我与女友一气之下,索性于次日凌晨5点多赶紧退房,搬到中央大街诺曼弟酒店入住套房,虽房价多贴20多元,房型却比这\"烂远达\"大上3倍之多,诺曼弟酒店不仅地段好(若从远达打D到中央大街还要多花14元~\"~),前台服务更好!...奉劝各位要入住远达的网友,千万要三思阿!'} {'label': 1, 'review': '住的是8楼豪海房，每天就在海边度过，一个字，爽！酒店服务不错，路上遇见都会微笑问好，早餐还算丰富，而且到11点，可以一起解决午餐问题。大堂很有特色，喜欢，还有它家的沙滩拖鞋很舒服，想买双回家，就是不对外卖。房间有点陈旧，床很舒服，上网费用高了点。一点小问题时浴室淋浴房的下面封条有漏水，害得上厕所都会有影响，鞋子湿湿的，要用毛巾垫着才行，和客房服务提出后也几天也没有解决。'}\n",
      "{'label': 1, 'review': '别墅型的酒店，非常特别,离海边很近.消费很平价'} {'label': 1, 'review': '服务人员素质好,彬彬有礼.软硬件都很好的酒店,早餐有很好的西餐,也有当地传统小吃,值得一住.'}\n",
      "{'label': 0, 'review': '前台的人该好好上上培训课了,永远一张扑克脸,我是顾客又没借你钱,干吗要看你脸色.房间的设施越来越旧,洗手间的毛巾该换了,如果不是因为方便工作以这样的价格绝对不会考虑入住.以前住了很多次,以后会考虑换酒店.还有评论真的有用吗?入住别的酒店留评论以后都会看到酒店管理层的回复,比如大连的银帆酒店.新协通的回复怎么从没看到过,所以才会没改进.酒店管理层自己都不思上进何况下属.'} {'label': 0, 'review': '差，太差，极其的差，虽能说明这将酒店的情况。服务差、房间差、设备差，水质和周围环境更差。差的令人发指。'}\n",
      "{'label': 1, 'review': '房间整洁，干净，携程价位不算高。周边环境一流，是个修身养性的好地方。'} {'label': 1, 'review': '还不错，应该比较符合三星级标准，不算太贵，可能是和携程的签约价格！'}\n",
      "{'label': 0, 'review': '酒店的星级与实际不符,房间相当与好一点的招待所,交通也不方便.住的不爽!'} {'label': 1, 'review': '1。环境不错，不远就是三峡广场，无聊可以去看看美女2。早餐，赞！3。结帐速度较慢总的来说，还是不错的'}\n",
      "{'label': 1, 'review': '即便是江阴星级最高的酒店,但还是摆脱不了土的感觉,装修一般,早餐更是一般,对服务没有什么深刻的体会,相信如果有跨国酒店可以选择,应该会有进步.'} {'label': 1, 'review': '酒店的服务总的来说还是不错的，上网的速度也很快，下次还会住。只是携程的价格还是偏高，商务楼层598，我的客户可以订到同样的房间只要500元。'}\n",
      "{'label': 1, 'review': '非常不错的酒店，依山傍水，里面大片森林，散散步很不错，坐在湖边也休息也是不错的选择；房间很幽静，房间的设施很好，服务员态度也很好。'} {'label': 0, 'review': '服务员太差，房间很吵，隔音不好，房间味道很重，很一般，不如稀土国际大酒店好，收费有低，还是四星，服务很好，离火车站方便'}\n",
      "{'label': 1, 'review': '因为之前查看了携程的点评，所以对这家酒店的期望值并不高。但入住以后总体来说感觉还可以，虽说照五星级还有差距，但在吉林应该可以接受。酒店周围好像没什么合适的饭店，最后还是在酒店吃了巴西烤肉自助，比其他地方贵些88元/位，水平一般。还有一个就是卫生间确实小。'} {'label': 0, 'review': '9月23日的值班经理（女的）很牛啊！我当天由于航班原因早晨3点57分到的酒店，我订的是8点岛（携程最早的到达时间）在服务员的允许下进入酒店房间，当时并未提出要加收费用，收了我500押金。中午值班经理（女的）却突然打电话到我房间，说我必须再交一天的费用，我据理力争，对她说你们的服务员应该有告知义务，如果你事先说好，我同意，你收多少多不算多！她竟然说和你讲不清楚，挂了我电话。后又让当天的服务员打电话到我房间，后在我的质问下他也承认了是他的错误，并愿承担我的损失。我当即和值班经理联系，但她竟然说，这是我处理的和他没关系，你一定要付。我当即提出退房（当时9点），她竟然说你现在退我也要收你一天半的房钱。并说这是酒店规定，我说你拿出来给我看，她竟然回答我这是保密的。我下楼退了房间，我要她的名字，并告知她，我要投诉你的，她竟然说我没有必要告诉你我的名字，我是经理！牛啊。这样的服务态度竟然还是管理人员，可想而知她管理的人员将以什么样的态度去为客户服务！补充点评2006年10月4日：这个酒店真得没办法用语言来形容了。还是希望各位管好自己的钱包，免得被收了钱还不知道怎么回事！各位最好的办法就是不要去住，否则你就不知道到底为了什么付的钱！请多多转告！'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(datasets[\"train\"][i],datasets[\"test\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5 创建Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 6988\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 777\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")\n",
    "\n",
    "def process_function(examples):\n",
    "    tokenized_examples = tokenizer(examples[\"review\"], max_length=128, truncation=True)\n",
    "    tokenized_examples[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized_examples\n",
    "\n",
    "tokenized_datasets = datasets.map(process_function, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101,\n",
       "  2769,\n",
       "  3221,\n",
       "  1724,\n",
       "  3299,\n",
       "  1159,\n",
       "  1343,\n",
       "  4638,\n",
       "  3918,\n",
       "  1766,\n",
       "  511,\n",
       "  2769,\n",
       "  6370,\n",
       "  4638,\n",
       "  3221,\n",
       "  6498,\n",
       "  1290,\n",
       "  1947,\n",
       "  2791,\n",
       "  8024,\n",
       "  2458,\n",
       "  1993,\n",
       "  1762,\n",
       "  5381,\n",
       "  677,\n",
       "  2458,\n",
       "  6983,\n",
       "  2421,\n",
       "  3173,\n",
       "  6163,\n",
       "  934,\n",
       "  1400,\n",
       "  4638,\n",
       "  4212,\n",
       "  4275,\n",
       "  2923,\n",
       "  1429,\n",
       "  2471,\n",
       "  4638,\n",
       "  8024,\n",
       "  852,\n",
       "  1057,\n",
       "  857,\n",
       "  1400,\n",
       "  2798,\n",
       "  1355,\n",
       "  4385,\n",
       "  3418,\n",
       "  3315,\n",
       "  679,\n",
       "  3221,\n",
       "  6929,\n",
       "  3416,\n",
       "  4638,\n",
       "  511,\n",
       "  7370,\n",
       "  749,\n",
       "  1920,\n",
       "  1851,\n",
       "  3300,\n",
       "  6163,\n",
       "  934,\n",
       "  6814,\n",
       "  4638,\n",
       "  2697,\n",
       "  6230,\n",
       "  1912,\n",
       "  8024,\n",
       "  3517,\n",
       "  2231,\n",
       "  1469,\n",
       "  2791,\n",
       "  7313,\n",
       "  6963,\n",
       "  6820,\n",
       "  3221,\n",
       "  5439,\n",
       "  3416,\n",
       "  2094,\n",
       "  8024,\n",
       "  2523,\n",
       "  3191,\n",
       "  8024,\n",
       "  2130,\n",
       "  1059,\n",
       "  3766,\n",
       "  3300,\n",
       "  6163,\n",
       "  934,\n",
       "  6814,\n",
       "  511,\n",
       "  1061,\n",
       "  4636,\n",
       "  1914,\n",
       "  4638,\n",
       "  2791,\n",
       "  6589,\n",
       "  5042,\n",
       "  4684,\n",
       "  2218,\n",
       "  3221,\n",
       "  3857,\n",
       "  6589,\n",
       "  8024,\n",
       "  678,\n",
       "  3613,\n",
       "  679,\n",
       "  833,\n",
       "  1762,\n",
       "  857,\n",
       "  749,\n",
       "  511,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "trainset, validset = tokenized_datasets[\"train\"], tokenized_datasets[\"test\"]\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=DataCollatorWithPadding(tokenizer))\n",
    "validloader = DataLoader(validset, batch_size=64, shuffle=False, collate_fn=DataCollatorWithPadding(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101,  671, 5663,  ...,    0,    0,    0],\n",
       "        [ 101, 1184, 1378,  ...,    0,    0,    0],\n",
       "        [ 101, 1057,  857,  ..., 4638, 4510,  102],\n",
       "        ...,\n",
       "        [ 101, 1139, 2345,  ...,    0,    0,    0],\n",
       "        [ 101, 6983, 2421,  ..., 2769, 6230,  102],\n",
       "        [ 101, 2791, 7313,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enumerate(trainloader))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step6 创建模型及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hfl/rbt3\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step7 训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in validloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            output = model(**batch)\n",
    "            pred = torch.argmax(output.logits, dim=-1)\n",
    "            acc_num += (pred.long() == batch[\"labels\"].long()).float().sum()\n",
    "    return acc_num / len(validset)\n",
    "\n",
    "\n",
    "def train(epoch=3, log_step=100):\n",
    "    global_step = 0\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for batch in trainloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "            if global_step % log_step == 0:\n",
    "                print(f\"ep: {ep}, global_step: {global_step}, loss: {output.loss.item()}\")\n",
    "            global_step += 1\n",
    "        acc = evaluate()\n",
    "        print(f\"ep: {ep}, acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, global_step: 0, loss: 0.6987050771713257\n",
      "ep: 0, global_step: 100, loss: 0.3915312886238098\n",
      "ep: 0, global_step: 200, loss: 0.23195083439350128\n",
      "ep: 0, acc: 0.8931788802146912\n",
      "ep: 1, global_step: 300, loss: 0.15785916149616241\n",
      "ep: 1, global_step: 400, loss: 0.34245699644088745\n",
      "ep: 1, acc: 0.8983269333839417\n",
      "ep: 2, global_step: 500, loss: 0.15504734218120575\n",
      "ep: 2, global_step: 600, loss: 0.23264743387699127\n",
      "ep: 2, acc: 0.9009009003639221\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step9 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：我觉得这家酒店不错，饭很好吃！\n",
      "模型预测结果:好评！\n",
      "Score:0.9958785772323608\n"
     ]
    }
   ],
   "source": [
    "sen = \"我觉得这家酒店不错，饭很好吃！\"\n",
    "id2_label = {0: \"差评！\", 1: \"好评！\"}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors=\"pt\")\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits, dim=-1)\n",
    "    score = torch.softmax(logits, dim=-1)\n",
    "    print(f\"输入：{sen}\\n模型预测结果:{id2_label.get(pred.item())}\\nScore:{score[0][pred.item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model.config.id2label = id2_label\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '好评！', 'score': 0.9958785772323608}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '差评！', 'score': 0.9502854943275452}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"污渍不行\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
