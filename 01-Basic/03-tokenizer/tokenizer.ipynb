{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TokenizeråŸºæœ¬ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§æ¢¦æƒ³\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 åŠ è½½ä¸ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä»huggingfaceåŠ è½½ï¼Œè¾“å…¥æ¨¡å‹åç§°ï¼Œå³å¯åŠ è½½å¯¹åº”çš„åˆ†è¯å™¨\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./roberta_tokenizer\\\\tokenizer_config.json',\n",
       " './roberta_tokenizer\\\\special_tokens_map.json',\n",
       " './roberta_tokenizer\\\\vocab.txt',\n",
       " './roberta_tokenizer\\\\added_tokens.json',\n",
       " './roberta_tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizerä¿å­˜åˆ°æœ¬åœ°\n",
    "tokenizer.save_pretrained(\"./roberta_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä»æœ¬åœ°åŠ è½½tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./roberta_tokenizer\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 å¥å­åˆ†è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['å¼±', 'å°', 'çš„', 'æˆ‘', 'ä¹Ÿ', 'æœ‰', 'å¤§', 'æ¢¦', 'æƒ³']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sen)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 æŸ¥çœ‹è¯å…¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##æœ•': 16362,\n",
       " 'å€': 945,\n",
       " 'ç¿©': 5431,\n",
       " 'è†': 5601,\n",
       " '63': 8381,\n",
       " '##è¤«': 19250,\n",
       " '##ola': 12653,\n",
       " '##æš«': 16328,\n",
       " 'å‰': 1186,\n",
       " 'docomo': 11358,\n",
       " '##å †': 14888,\n",
       " 'ç¼º': 5375,\n",
       " 'edward': 12259,\n",
       " '##line': 8762,\n",
       " 'å¡¢': 1854,\n",
       " 'ç¼­': 5369,\n",
       " 'å': 1345,\n",
       " 'æ’…': 3049,\n",
       " '##ology': 10277,\n",
       " 'alt': 9721,\n",
       " '##è¬¬': 19402,\n",
       " 'è¯±': 6430,\n",
       " 'ç¨¿': 4943,\n",
       " '699': 10439,\n",
       " '##ague': 12998,\n",
       " 'çŒ': 4340,\n",
       " '##ç¢§': 17876,\n",
       " '##ç´°': 18226,\n",
       " '##ç‚™': 17204,\n",
       " '##è¿': 19873,\n",
       " 'æ–‘': 3157,\n",
       " 'å©‰': 2039,\n",
       " 'chicago': 10268,\n",
       " '##é“²': 20268,\n",
       " 'æ': 2934,\n",
       " 'wma': 9900,\n",
       " 'å®™': 2136,\n",
       " '##éš ': 20455,\n",
       " 'å­«': 2113,\n",
       " '-': 118,\n",
       " '##é›': 20477,\n",
       " '##é» ': 21011,\n",
       " '##è““': 18960,\n",
       " 'éª¸': 7760,\n",
       " '##åœƒ': 14804,\n",
       " '##ç¡': 17853,\n",
       " 'æ¨¾': 3575,\n",
       " 'ä¹©': 742,\n",
       " 'ï½¡': 8081,\n",
       " 'dog': 13030,\n",
       " '##é’“': 20214,\n",
       " 'å­™': 2101,\n",
       " '##ity': 8863,\n",
       " '##è¢«': 19215,\n",
       " 'å¸†': 2359,\n",
       " 'instagram': 8780,\n",
       " '##å§': 15060,\n",
       " 'å•†': 1555,\n",
       " '##å²š': 15326,\n",
       " '##å½­': 15567,\n",
       " '##world': 10120,\n",
       " '##æ¾€': 17123,\n",
       " 'ç¹©': 5256,\n",
       " '##â‘©': 13565,\n",
       " 'è¦': 6211,\n",
       " '##ads': 12514,\n",
       " '##ä¼': 13882,\n",
       " '##æš„': 16315,\n",
       " '##è¥': 19254,\n",
       " 'åº¹': 2436,\n",
       " 'å•¼': 1582,\n",
       " 'ï¼œ': 8040,\n",
       " '##ä¸': 13736,\n",
       " '##é™': 20418,\n",
       " 'å£': 1880,\n",
       " 'å›': 1719,\n",
       " 'æ°´': 3717,\n",
       " 'null': 12083,\n",
       " '##å†›': 14149,\n",
       " '##ç›ˆ': 17716,\n",
       " 'è£¤': 6175,\n",
       " 'è€': 5767,\n",
       " 'è·ª': 6661,\n",
       " 'çš†': 4639,\n",
       " '##Ã—': 9569,\n",
       " 'è»½': 6731,\n",
       " '<T>': 105,\n",
       " '##æ‹¾': 15953,\n",
       " '##é˜Ÿ': 20396,\n",
       " '[unused28]': 28,\n",
       " '##é›€': 20468,\n",
       " '1911': 10041,\n",
       " '##å—‘': 14679,\n",
       " '##åºŠ': 15471,\n",
       " '##ç‹°': 17384,\n",
       " '##99': 8653,\n",
       " 'è´': 6564,\n",
       " 'è‰˜': 5675,\n",
       " '1884': 13007,\n",
       " 'å«š': 2071,\n",
       " 'v': 164,\n",
       " '##ã®ãŠ': 10217,\n",
       " '##å¯†': 15223,\n",
       " '##â†': 13018,\n",
       " '##æŠ¤': 15901,\n",
       " '##é¥¨': 20703,\n",
       " 'ç”«': 4502,\n",
       " 'pinkoi': 11941,\n",
       " 'lady': 8822,\n",
       " '##æŸ±': 16450,\n",
       " 'å™¸': 1697,\n",
       " 'beta': 9861,\n",
       " '##ç‘™': 17501,\n",
       " '##ä¸¿': 13773,\n",
       " '##å¥‘': 15000,\n",
       " 'è£¸': 6180,\n",
       " '##è©': 18892,\n",
       " 'æ§˜': 3545,\n",
       " '##æ°¸': 16776,\n",
       " '##é¦': 20727,\n",
       " '##ï¾„': 21114,\n",
       " 'ç›–': 4667,\n",
       " '##å†ˆ': 14139,\n",
       " '##èª¬': 19361,\n",
       " 'æš': 2611,\n",
       " '##ã‚ˆã£ã¦': 12957,\n",
       " '##é°“': 20870,\n",
       " 'ä¿³': 937,\n",
       " 'for': 8330,\n",
       " '##åª³': 15117,\n",
       " '##èŒœ': 18809,\n",
       " 'ç¨”': 4926,\n",
       " '##éƒ½': 20020,\n",
       " 'å—': 1408,\n",
       " '##è›†': 19082,\n",
       " 'éº¥': 7930,\n",
       " '##æ¥¹': 16573,\n",
       " 'ç³Ÿ': 5136,\n",
       " '##ç–': 17605,\n",
       " '##è‡ª': 18689,\n",
       " 'ç‘œ': 4447,\n",
       " 'æ…§': 2716,\n",
       " 'é²¨': 7835,\n",
       " 'è³': 5477,\n",
       " 'wx17house': 9973,\n",
       " 'å®': 1340,\n",
       " 'ç¾²': 5414,\n",
       " '##ä»•': 13856,\n",
       " 'å¨‡': 2019,\n",
       " 'âˆ€': 376,\n",
       " 'â“˜': 426,\n",
       " 'æ†‹': 2728,\n",
       " 'ç˜¸': 4613,\n",
       " 'road': 9772,\n",
       " 'butler': 11797,\n",
       " '##mix': 11091,\n",
       " '##å‘¦': 14509,\n",
       " 'å˜©': 1666,\n",
       " 'Â¼': 189,\n",
       " '402': 12040,\n",
       " '##å«£': 15130,\n",
       " '##ç»€': 18354,\n",
       " 'æ“¾': 3101,\n",
       " 'æµ¦': 3855,\n",
       " '##ÃŸ': 13361,\n",
       " '##åš¥': 14767,\n",
       " '##é': 19941,\n",
       " 'æ²¹': 3779,\n",
       " '##gnet': 13308,\n",
       " 'é¹‘': 7906,\n",
       " 'cake': 11683,\n",
       " 'ç©†': 4946,\n",
       " '##å¼ƒ': 15518,\n",
       " 'å™': 1679,\n",
       " 'chen': 9798,\n",
       " 'å¹¸': 2401,\n",
       " '##æ­': 16683,\n",
       " 'å¼‚': 2460,\n",
       " 'é˜‘': 7332,\n",
       " '##97': 9410,\n",
       " '##æ‹±': 15947,\n",
       " 'cheese': 11387,\n",
       " 'ç°Œ': 5078,\n",
       " '##èƒ±': 18594,\n",
       " 'ç‘°': 4456,\n",
       " 'install': 12461,\n",
       " '79': 8428,\n",
       " 'ç¢©': 4820,\n",
       " 'ç®•': 5049,\n",
       " 'è³„': 6535,\n",
       " '##page': 11817,\n",
       " 'çŸ£': 4760,\n",
       " '##ther': 10198,\n",
       " '##ç¿˜': 18483,\n",
       " '3d': 8219,\n",
       " 'éŠ·': 7077,\n",
       " 'éª…': 7735,\n",
       " 'å’†': 1467,\n",
       " 'ç—•': 4575,\n",
       " 'å­•': 2097,\n",
       " 'é“…': 7192,\n",
       " '##æ¼©': 17090,\n",
       " 'â””': 435,\n",
       " '##ç¯': 17185,\n",
       " '1939': 9459,\n",
       " 'ğŸ”¥': 8103,\n",
       " 'ç‰‡': 4275,\n",
       " '##ç¸„': 18291,\n",
       " '013': 13034,\n",
       " '##ors': 10903,\n",
       " 'å’˜': 1478,\n",
       " '##é‡': 20079,\n",
       " 'æ‰‘': 2800,\n",
       " 'é•—': 7260,\n",
       " '##test': 11574,\n",
       " 'ç®—': 5050,\n",
       " '##log': 11458,\n",
       " '##åˆ©': 14221,\n",
       " '##åŠ': 14268,\n",
       " '##â’‰': 13572,\n",
       " '##æ»•': 17058,\n",
       " '##å«©': 15132,\n",
       " 'èƒº': 5542,\n",
       " '17': 8126,\n",
       " 'å¿˜': 2563,\n",
       " 'q': 159,\n",
       " 'å—…': 1618,\n",
       " 'æ·': 3349,\n",
       " 'é“¤': 7204,\n",
       " 'man': 8791,\n",
       " 'è½®': 6762,\n",
       " '##lus': 11131,\n",
       " '271': 11206,\n",
       " 'èœœ': 6057,\n",
       " 'é¢“': 7575,\n",
       " '##è„¾': 18626,\n",
       " '##è©¹': 19342,\n",
       " '##è«—': 19374,\n",
       " '##é·º': 20935,\n",
       " '##Â¹': 13357,\n",
       " 'ç¬¦': 5016,\n",
       " '##ste': 11881,\n",
       " '##å†•': 14146,\n",
       " '##æ¡ƒ': 16482,\n",
       " 'çŒœ': 4339,\n",
       " '##è£´': 19236,\n",
       " 'â™¥': 491,\n",
       " 'å¸·': 2381,\n",
       " 'ç©«': 4953,\n",
       " 'è¾½': 6808,\n",
       " 'é­': 7794,\n",
       " '##æ¼¢': 17088,\n",
       " '##å­š': 15159,\n",
       " 'æ”ª': 3115,\n",
       " 'é¹Œ': 7904,\n",
       " 'ç–†': 4538,\n",
       " 'å‡': 1285,\n",
       " 'é¨': 7696,\n",
       " '##å¤‡': 14963,\n",
       " 'ä½': 858,\n",
       " 'è„³': 5566,\n",
       " '##æºœ': 17034,\n",
       " 'çš“': 4645,\n",
       " '##æ°™': 16758,\n",
       " '##å»': 14400,\n",
       " 'æ‹–': 2870,\n",
       " '##ç»¥': 18381,\n",
       " '##çªŸ': 18031,\n",
       " 'è´¢': 6568,\n",
       " '##é‚„': 19974,\n",
       " 'å“ª': 1525,\n",
       " 'é™¶': 7378,\n",
       " '##æ­‰': 16681,\n",
       " 'ï¼': 8027,\n",
       " 'matt': 12042,\n",
       " '##æ’': 16018,\n",
       " 'è‚¿': 5514,\n",
       " 'â˜•': 482,\n",
       " 'young': 9802,\n",
       " 'å‰©': 1197,\n",
       " '##å¦': 14426,\n",
       " '##é•‚': 20308,\n",
       " 'èµ': 6605,\n",
       " 'ç°¦': 5081,\n",
       " 'è¹¬': 6700,\n",
       " '##ght': 9725,\n",
       " 'æ‹š': 2874,\n",
       " '##zl': 12961,\n",
       " '##è‚¡': 18557,\n",
       " 'æƒ‹': 2662,\n",
       " 'æ‚»': 2655,\n",
       " 'ç£¡': 4835,\n",
       " 'é™‹': 7358,\n",
       " 'é©¼': 7729,\n",
       " '1919': 9915,\n",
       " 'æ¾„': 4067,\n",
       " 'ç»­': 5330,\n",
       " 'é‡‘': 7032,\n",
       " '##tc': 10149,\n",
       " '##um': 8545,\n",
       " '##æ¡': 15996,\n",
       " 'facebooktwitterpinterestgoogle': 11498,\n",
       " 'å‹˜': 1242,\n",
       " '##æµ‡': 16899,\n",
       " 'æ¥µ': 3513,\n",
       " 'å›¢': 1730,\n",
       " 'å»š': 2446,\n",
       " 'çš®': 4649,\n",
       " 'zol': 12182,\n",
       " '06': 8116,\n",
       " '##ä¸¥': 13755,\n",
       " 'æ¶': 3002,\n",
       " 'è–': 5829,\n",
       " '##bert': 10491,\n",
       " '##ã‚­ãƒ³ã‚¯': 11505,\n",
       " '##åŠ‡': 14263,\n",
       " 'è': 5827,\n",
       " '##ç­Š': 18081,\n",
       " '98': 8327,\n",
       " 'plc': 10015,\n",
       " 'èœ´': 6062,\n",
       " 'å½’': 2495,\n",
       " 'å€’': 948,\n",
       " 'è¸ª': 6679,\n",
       " 'pmi': 10127,\n",
       " 'â–²topjan': 10601,\n",
       " 'è…•': 5580,\n",
       " 'forest': 10889,\n",
       " 'ä½‘': 859,\n",
       " '##é›¨': 20490,\n",
       " 'å‹ƒ': 1234,\n",
       " 'hall': 11049,\n",
       " '##å£¢': 14948,\n",
       " 'å“’': 1515,\n",
       " '##éœ¸': 20521,\n",
       " 'åŒª': 1272,\n",
       " 'å’Œ': 1469,\n",
       " '6a': 11692,\n",
       " '##å‚­': 14056,\n",
       " 'å—¯': 1638,\n",
       " '##å¬¤': 15142,\n",
       " 'é¸¦': 7887,\n",
       " '##tb': 11126,\n",
       " '##æ€': 15635,\n",
       " '##æ¸©': 17003,\n",
       " 'æ‹¼': 2894,\n",
       " 'discuz': 13197,\n",
       " '##é…': 20039,\n",
       " '##äº‚': 13805,\n",
       " '##ã‚ã‚Šã¾ã™': 10700,\n",
       " 'æ¸©': 3946,\n",
       " 'é‘«': 7144,\n",
       " 'ç¸': 4366,\n",
       " 'æ…˜': 2711,\n",
       " 'div': 11308,\n",
       " '##é’': 20220,\n",
       " '##éº“': 20983,\n",
       " 'ç…œ': 4207,\n",
       " 'ç²¹': 5122,\n",
       " '##èš¯': 19078,\n",
       " 'è¯': 6413,\n",
       " '##æ¶µ': 16948,\n",
       " '##çŠ¬': 17362,\n",
       " 'âœ¿': 504,\n",
       " '##è‘‰': 18921,\n",
       " 'ç¶¦': 5201,\n",
       " '##å°‰': 15259,\n",
       " '##rant': 10834,\n",
       " 'se': 9342,\n",
       " '##âˆ™': 13531,\n",
       " '##æŸš': 16441,\n",
       " 'æ°¢': 3705,\n",
       " 'è¾Ÿ': 6792,\n",
       " 'å¹„': 2387,\n",
       " 'è©£': 6274,\n",
       " 'è¹„': 6686,\n",
       " '##è·': 19712,\n",
       " 'wwdc': 12848,\n",
       " '##å«–': 15126,\n",
       " '##æ©': 16030,\n",
       " '##é©›': 20769,\n",
       " '##hy': 9943,\n",
       " 'çŠ„': 4299,\n",
       " 'âŒ’': 404,\n",
       " '12345': 9700,\n",
       " 'æ“š': 3087,\n",
       " 'price': 11597,\n",
       " 'redis': 12599,\n",
       " '##å¼“': 15526,\n",
       " '##æµª': 16914,\n",
       " 'æ‘»': 3046,\n",
       " '##ã‚': 10063,\n",
       " '50cm': 11721,\n",
       " '##éœ': 20516,\n",
       " '##æ¶': 16081,\n",
       " '##cker': 10603,\n",
       " '##â‘¶': 13568,\n",
       " 'è…': 5797,\n",
       " '##èµ¦': 19677,\n",
       " 'è¥': 5785,\n",
       " 'é³¥': 7852,\n",
       " 'æµ·': 3862,\n",
       " 'å‹•': 1240,\n",
       " 'å˜»': 1677,\n",
       " 'è¡²': 6140,\n",
       " '##é»œ': 21008,\n",
       " '##520': 13241,\n",
       " '##é’': 20212,\n",
       " '##ç©©': 18009,\n",
       " '##â‰§': 13548,\n",
       " '##ç§¯': 17973,\n",
       " '##éº—': 20984,\n",
       " '##~': 13347,\n",
       " 'å“¦': 1521,\n",
       " '##dar': 12354,\n",
       " 'è€—': 5450,\n",
       " 'äº•': 759,\n",
       " '##é§•': 20747,\n",
       " 'how': 9510,\n",
       " '##ç»¼': 18398,\n",
       " '##é‚¨': 19988,\n",
       " 'æ®’': 3656,\n",
       " '##æ°¨': 16767,\n",
       " '##â–«': 13608,\n",
       " '##è°¦': 19529,\n",
       " '##è©¬': 19335,\n",
       " '##é…¥': 20046,\n",
       " '##èƒ›': 18582,\n",
       " 'ç»¼': 5341,\n",
       " '##è‘¦': 18927,\n",
       " '##å‘': 14460,\n",
       " 'ç': 4712,\n",
       " '##ç›‚': 17712,\n",
       " 'ç©¢': 4951,\n",
       " 'å‹³': 1251,\n",
       " 'x86': 10652,\n",
       " '##eh': 12742,\n",
       " '##å’±': 14550,\n",
       " 'å…š': 1054,\n",
       " 'æ—': 3184,\n",
       " '##æ¶‡': 16923,\n",
       " '##çŒ–': 17392,\n",
       " '##è‚¿': 18571,\n",
       " '##èºŠ': 19768,\n",
       " 'è‡¼': 5639,\n",
       " 'æ·‘': 3902,\n",
       " '##å—¤': 14690,\n",
       " '##è‡“': 18682,\n",
       " '##coin': 10160,\n",
       " 'å•–': 1561,\n",
       " 'financial': 12200,\n",
       " '##å‰': 14452,\n",
       " 'çŸ': 4754,\n",
       " '##å¨¼': 15092,\n",
       " '##å„˜': 14086,\n",
       " 'æ°¹': 3720,\n",
       " 'éŒ': 7088,\n",
       " 'å½±': 2512,\n",
       " 'false': 11457,\n",
       " '##ã': 8763,\n",
       " '##ç«¯': 18056,\n",
       " 'ã‚µ': 603,\n",
       " 'å’¸': 1496,\n",
       " 'apple': 8350,\n",
       " '##Â®': 8646,\n",
       " '##è²Œ': 19562,\n",
       " '1965': 9141,\n",
       " '##è‹»': 18799,\n",
       " 'ddd': 13234,\n",
       " '##å«‚': 15121,\n",
       " 'cba': 10912,\n",
       " '##çª¥': 18033,\n",
       " 'å§Š': 1992,\n",
       " '##yi': 11017,\n",
       " '##æ¶£': 16938,\n",
       " 'æœ¯': 3318,\n",
       " '##èŸ’': 19154,\n",
       " '513': 13310,\n",
       " '##ä¼¦': 13897,\n",
       " 'æ¼¯': 4037,\n",
       " '##é†‹': 20062,\n",
       " 'áµ˜': 336,\n",
       " 'åˆƒ': 1145,\n",
       " '##èª¡': 19354,\n",
       " 'ã‚’ã“': 10074,\n",
       " '1916': 10772,\n",
       " 'tel': 11108,\n",
       " '399': 9612,\n",
       " 'cool': 11338,\n",
       " '##é¢': 20630,\n",
       " '##è›': 19087,\n",
       " '##ary': 9277,\n",
       " 'jimmy': 10317,\n",
       " 'æ¸': 3939,\n",
       " '##tant': 12028,\n",
       " '##ç¢£': 17875,\n",
       " 'save': 13069,\n",
       " 'éº': 7928,\n",
       " 'v9': 11894,\n",
       " 'message': 12231,\n",
       " 'ä¼º': 848,\n",
       " '##åŠ±': 14282,\n",
       " '##å…¥': 14114,\n",
       " '##åˆ½': 14232,\n",
       " 'åº¾': 2437,\n",
       " '##æƒ ': 15726,\n",
       " '##æ»·': 17075,\n",
       " 'è·': 5815,\n",
       " '##çƒ¬': 17234,\n",
       " 'ã‚ã›': 11878,\n",
       " 'river': 10835,\n",
       " '##è·¹': 19723,\n",
       " '##è·©': 19717,\n",
       " 'ç„¦': 4193,\n",
       " 'è¾—': 6786,\n",
       " '1971': 9061,\n",
       " '##è€¨': 18511,\n",
       " 'music': 9057,\n",
       " 'f1': 9080,\n",
       " '##æŸ©': 16447,\n",
       " '##et': 8418,\n",
       " '##å©†': 15095,\n",
       " 'è£†': 6164,\n",
       " '##è³ˆ': 19594,\n",
       " 'é‰‘': 7058,\n",
       " 'é›‹': 7418,\n",
       " '##ç¾¹': 18473,\n",
       " '##è¾«': 19854,\n",
       " 'æ‰¦': 2808,\n",
       " '##æ›¸': 16349,\n",
       " 'å•¥': 1567,\n",
       " 'harry': 12296,\n",
       " '##ç•´': 17590,\n",
       " 'æŒŸ': 2911,\n",
       " 'éœ': 7453,\n",
       " '##åš': 14857,\n",
       " '25000': 13251,\n",
       " '##å¤¹': 14988,\n",
       " '##è¿™': 19878,\n",
       " '##å…»': 14132,\n",
       " 'æ ©': 3414,\n",
       " 'æ¿’': 4085,\n",
       " 'è¬—': 6339,\n",
       " 'ä¸ª': 702,\n",
       " 'æ®¿': 3671,\n",
       " 'ç¬›': 5013,\n",
       " 'ç´º': 5172,\n",
       " 'çº¿': 5296,\n",
       " 'ï½‹': 8061,\n",
       " 'ç¿': 4729,\n",
       " 'æ …': 3402,\n",
       " 'æ¢Ÿ': 3455,\n",
       " 'æ¸ ': 3940,\n",
       " 'é”': 7228,\n",
       " 'nb': 9254,\n",
       " 'çƒ«': 4176,\n",
       " 'well': 12010,\n",
       " 'åƒ§': 1014,\n",
       " 'å°•': 2210,\n",
       " 'é¹‰': 7902,\n",
       " '##ome': 9893,\n",
       " 'ä½µ': 882,\n",
       " 'ç²¤': 5113,\n",
       " '##os': 8470,\n",
       " '##sc': 10203,\n",
       " 'â˜…â˜…â˜…â˜…': 11815,\n",
       " '##fw': 12851,\n",
       " '##å®¡': 15201,\n",
       " '##æ‡¶': 15811,\n",
       " '##ç¥‡': 17913,\n",
       " '##è¾©': 19853,\n",
       " '##é…©': 20047,\n",
       " '##é™²': 20432,\n",
       " 'å': 1776,\n",
       " 'ç›´': 4684,\n",
       " '##é‰‘': 20115,\n",
       " '##é¸µ': 20950,\n",
       " '##ä¹’': 13785,\n",
       " '##å“‘': 14571,\n",
       " 'æ‚ª': 2646,\n",
       " '##æ­': 16079,\n",
       " '##lution': 11843,\n",
       " '##ç¨œ': 17986,\n",
       " '##æœˆ': 16356,\n",
       " '##è¼•': 19795,\n",
       " 'ç±': 5093,\n",
       " '##è‚†': 18544,\n",
       " '##æ°°': 16772,\n",
       " 'å': 1282,\n",
       " '##èˆ': 18716,\n",
       " '##29': 8887,\n",
       " '##å¤š': 14971,\n",
       " '##atus': 12283,\n",
       " '##è’¼': 18952,\n",
       " '##ã¨': 8322,\n",
       " '##ook': 10176,\n",
       " '##xy': 11038,\n",
       " '##å‰': 14383,\n",
       " 'ã‚ˆ': 577,\n",
       " '##æ³®': 16860,\n",
       " 'â‘ ': 405,\n",
       " 'äº¢': 768,\n",
       " 'banner': 13256,\n",
       " '##å‹¢': 14305,\n",
       " '##è°‘': 19513,\n",
       " '##é³ƒ': 20899,\n",
       " '##å¨…': 15074,\n",
       " '##æ¼‚': 17080,\n",
       " '##â–¬': 13609,\n",
       " 'å­': 2105,\n",
       " 'å†’': 1088,\n",
       " 'å§¨': 2007,\n",
       " '##å©•': 15098,\n",
       " 'è¬€': 6331,\n",
       " '3300': 11543,\n",
       " '82': 8460,\n",
       " 'æ‰±': 2818,\n",
       " 'è®§': 6373,\n",
       " '##ä½³': 13938,\n",
       " 'ç‚­': 4151,\n",
       " 'ç¼ ': 5362,\n",
       " 'é¥²': 7654,\n",
       " 'è€·': 5457,\n",
       " '266': 9674,\n",
       " '4200': 12395,\n",
       " 'æ’®': 3065,\n",
       " '##alk': 11346,\n",
       " 'è•­': 5941,\n",
       " 'ï½Œ': 8062,\n",
       " '##è’œ': 18943,\n",
       " '##çŠ': 17355,\n",
       " '##éš»': 20464,\n",
       " '950': 10468,\n",
       " 'å†': 1325,\n",
       " '1940': 9211,\n",
       " 'dec': 9333,\n",
       " 'è’¼': 5895,\n",
       " '##å›º': 14800,\n",
       " '##å¼‚': 15517,\n",
       " '##sa': 8606,\n",
       " '##ç´€': 18202,\n",
       " '##rp': 9980,\n",
       " 'å¼': 2459,\n",
       " 'gov': 9514,\n",
       " '##å›´': 14798,\n",
       " '##éƒ¦': 20011,\n",
       " 'æ¢¢': 3456,\n",
       " '##æ—¢': 16245,\n",
       " 'gis': 12892,\n",
       " '42': 8239,\n",
       " '[unused82]': 82,\n",
       " '251': 10924,\n",
       " 'disney': 12299,\n",
       " '##0mm': 12483,\n",
       " 'scott': 10692,\n",
       " 'alan': 11648,\n",
       " '818': 12265,\n",
       " '##ä¿®': 13991,\n",
       " '##æŠ¡': 15899,\n",
       " 'è©¦': 6275,\n",
       " 'macd': 10851,\n",
       " 'é‡Š': 7025,\n",
       " '1888': 10988,\n",
       " 'mozilla': 11579,\n",
       " '##ã€‡': 13649,\n",
       " 'ç‚¹': 4157,\n",
       " 'ï¸¿': 7995,\n",
       " '##èš“': 19070,\n",
       " 'å—Ÿ': 1630,\n",
       " 'èœš': 6056,\n",
       " '##ç…': 17788,\n",
       " '##fx': 13122,\n",
       " '##å³‡': 15337,\n",
       " '##å–‚': 14642,\n",
       " 'ç»': 4390,\n",
       " 'è•': 5930,\n",
       " '##å“ª': 14582,\n",
       " 'å‚©': 997,\n",
       " '##æ¸¥': 17001,\n",
       " 'f3': 11651,\n",
       " 'å™”': 1683,\n",
       " '##è•©': 18996,\n",
       " 'mx': 11171,\n",
       " '##ç‡¿': 17311,\n",
       " '##é’Ÿ': 20221,\n",
       " 'é—¡': 7303,\n",
       " '##æˆ´': 15842,\n",
       " '##81': 9313,\n",
       " 'mar': 9118,\n",
       " '13': 8124,\n",
       " 'è‚¯': 5507,\n",
       " '##own': 11751,\n",
       " '##ä¸‹': 13735,\n",
       " 'éŠ…': 7067,\n",
       " 'å–®': 1606,\n",
       " 'æ·š': 3907,\n",
       " 'ã«ã¯': 8738,\n",
       " 'group': 9051,\n",
       " 'éˆ´': 7051,\n",
       " '##èŒ¨': 18811,\n",
       " 'site': 11215,\n",
       " '52kb': 12811,\n",
       " 'è±ˆ': 6488,\n",
       " '##Ëˆ': 13372,\n",
       " 'çº¬': 5281,\n",
       " 'èˆ±': 5665,\n",
       " 'å‡º': 1139,\n",
       " '##äº¤': 13826,\n",
       " 'wi': 8541,\n",
       " '##å·¦': 15397,\n",
       " '##ç‘': 17177,\n",
       " '##è°¶': 19540,\n",
       " '##ï¹¡': 21068,\n",
       " '##è¦“': 19269,\n",
       " '##app': 11259,\n",
       " 'è¯„': 6397,\n",
       " 'bug': 8761,\n",
       " '##key': 9938,\n",
       " 'balance': 11606,\n",
       " '50mm': 11774,\n",
       " 'è°©': 6475,\n",
       " '##rio': 12062,\n",
       " '##5s': 13201,\n",
       " '##ãƒ«ãƒã‚¤ãƒˆ': 13304,\n",
       " '##æ·': 16006,\n",
       " '##ç„°': 17252,\n",
       " '##80': 8538,\n",
       " '##è¦§': 19273,\n",
       " 'ä»‹': 792,\n",
       " 'ebay': 8886,\n",
       " '##)': 13325,\n",
       " 'å·¦': 2340,\n",
       " 'çµ±': 5186,\n",
       " 'wind': 12302,\n",
       " '##æ°”': 16755,\n",
       " '801': 12566,\n",
       " 'ç—¨': 4585,\n",
       " '##ä¸': 13729,\n",
       " 'è®·': 6386,\n",
       " 'ã‚£': 590,\n",
       " '##ç™–': 17676,\n",
       " 'á…¢': 305,\n",
       " 'èµ‹': 6602,\n",
       " 'é”…': 7222,\n",
       " 'candy': 10653,\n",
       " '##æ®“': 16714,\n",
       " 'æ‹±': 2890,\n",
       " '##ãƒ•ãƒˆ': 10868,\n",
       " 'å‡¿': 1142,\n",
       " '##å€ª': 14017,\n",
       " 'â“’': 424,\n",
       " 'èª¨': 6302,\n",
       " '##è”­': 18980,\n",
       " '##è–¬': 19017,\n",
       " 'é¦‹': 7669,\n",
       " 'ÙŠ': 274,\n",
       " '##â…³': 13522,\n",
       " 'ç†’': 4222,\n",
       " 'è›­': 6036,\n",
       " 'ai': 8578,\n",
       " 'room': 10083,\n",
       " '##1000': 10529,\n",
       " '##å€¾': 14024,\n",
       " '##ç¬¹': 18076,\n",
       " '##ç»': 18362,\n",
       " '##è–°': 19019,\n",
       " '##è²ª': 19574,\n",
       " 'â–²topaug': 10558,\n",
       " '##æµ¬': 16915,\n",
       " 'network': 10339,\n",
       " 'earth': 11409,\n",
       " 'ç·©': 5227,\n",
       " '375': 11256,\n",
       " '##æš': 15668,\n",
       " '##tional': 11852,\n",
       " 'é°“': 7813,\n",
       " 'chapter': 12350,\n",
       " '##ä»»': 13875,\n",
       " '##åŠ¨': 14277,\n",
       " '##Ëš': 13378,\n",
       " 'æ“¡': 3090,\n",
       " '##è…': 18633,\n",
       " 'á…©': 311,\n",
       " '##è¡©': 19192,\n",
       " 'kanye': 8598,\n",
       " '##ç–¸': 17618,\n",
       " 'èº': 6708,\n",
       " 'ç„•': 4185,\n",
       " '##æ¤': 15671,\n",
       " 'é¢±': 7593,\n",
       " '1983': 8715,\n",
       " 'è®š': 6367,\n",
       " '##ä½š': 13923,\n",
       " 'ã‚¡': 588,\n",
       " '##ugh': 12667,\n",
       " '##èœ¢': 19116,\n",
       " '##å º': 14901,\n",
       " 'ç……': 4199,\n",
       " 'â”ƒ': 430,\n",
       " 'é¬†': 7777,\n",
       " '##æ™–': 16296,\n",
       " 'é¤®': 7632,\n",
       " '##bi': 9350,\n",
       " '185': 9560,\n",
       " 'node': 10320,\n",
       " '##ã—': 13727,\n",
       " 'èˆº': 5671,\n",
       " 'ubuntuforumwikilinuxpastechat': 12076,\n",
       " '##å‰Š': 14238,\n",
       " '##è°…': 19503,\n",
       " '##å»¢': 15507,\n",
       " 'æ©„': 3576,\n",
       " '[unused96]': 96,\n",
       " 'â–': 457,\n",
       " 'ç»“': 5310,\n",
       " '##bon': 12229,\n",
       " '##èª¥': 19357,\n",
       " 'el': 10245,\n",
       " 'code': 8700,\n",
       " 'ä¹ˆ': 720,\n",
       " '##æ·†': 16955,\n",
       " '##é‡œ': 20092,\n",
       " 'ğŸ˜': 8105,\n",
       " '##éŒ ': 20148,\n",
       " 'è': 5779,\n",
       " 'mind': 12573,\n",
       " 'Âº': 187,\n",
       " '##â…²': 13521,\n",
       " '##å¤¥': 14976,\n",
       " 'æ¨‘': 3558,\n",
       " '##ç›': 17718,\n",
       " 'æ‹’': 2867,\n",
       " 'è¥': 6197,\n",
       " 'ç¿’': 5424,\n",
       " '##å£‘': 14942,\n",
       " '##or': 8372,\n",
       " '##è¦º': 19278,\n",
       " '##012': 12037,\n",
       " '##é¡«': 20605,\n",
       " 'æ­': 2621,\n",
       " '##é—•': 20356,\n",
       " 'æ‘„': 3029,\n",
       " 'é‚º': 6942,\n",
       " 'å¬': 1374,\n",
       " 'åª›': 2056,\n",
       " 'æº…': 3972,\n",
       " '##è´¾': 19650,\n",
       " '##åŠ': 14272,\n",
       " '[unused41]': 41,\n",
       " '##å—½': 14701,\n",
       " '##è¼ª': 19800,\n",
       " 'zara': 10464,\n",
       " 'é€': 6861,\n",
       " '137': 9444,\n",
       " '##å': 14840,\n",
       " '##ç¼¨': 18423,\n",
       " '##è·ª': 19718,\n",
       " '##é€²': 19925,\n",
       " '##khz': 12112,\n",
       " '##é¤š': 20684,\n",
       " '##åš': 14760,\n",
       " 'lulu': 11970,\n",
       " 'ç­': 4361,\n",
       " 'tiger': 12088,\n",
       " '##3000': 13141,\n",
       " '080': 12365,\n",
       " 'æš«': 3271,\n",
       " 'äºº': 782,\n",
       " '##æ¹Š': 17014,\n",
       " '##Ù„': 13435,\n",
       " 'å¿': 1321,\n",
       " 'ngo': 11770,\n",
       " '787': 13029,\n",
       " 'ç±»': 5102,\n",
       " '##é‚‚': 19972,\n",
       " 'å››': 1724,\n",
       " 'åš®': 1712,\n",
       " '##è‚ ': 18556,\n",
       " 'ç­': 5026,\n",
       " 'ç±ƒ': 5091,\n",
       " 'å“¨': 1523,\n",
       " 'é±”': 7820,\n",
       " 'center': 9469,\n",
       " '##work': 12282,\n",
       " '##ç›¤': 17733,\n",
       " 'æ«š': 3603,\n",
       " '##çª¿': 18041,\n",
       " 'çˆ': 4394,\n",
       " '##å€‹': 14000,\n",
       " '##æ': 15990,\n",
       " 'sb': 12359,\n",
       " '##çªˆ': 18020,\n",
       " 'ç‰²': 4291,\n",
       " '##æº': 17035,\n",
       " 'å­¤': 2109,\n",
       " 'é«¦': 7771,\n",
       " '##sun': 11798,\n",
       " 'è‡»': 5638,\n",
       " '##çœ¸': 17761,\n",
       " '##è¸±': 19738,\n",
       " 'inside': 13157,\n",
       " '##se': 8417,\n",
       " 'æƒŸ': 2668,\n",
       " 'æ’«': 3062,\n",
       " 'æ¦»': 3536,\n",
       " '##ico': 10641,\n",
       " '360Â°': 11739,\n",
       " '##æŸ³': 16451,\n",
       " 'è§’': 6235,\n",
       " 'ãˆã‚‹': 10382,\n",
       " 'Ï†': 229,\n",
       " '##çª': 18017,\n",
       " '##è”—': 18972,\n",
       " 'æ·': 3908,\n",
       " '##å¾—': 15590,\n",
       " 'ç¥': 4860,\n",
       " '111': 8932,\n",
       " '##å´†': 15356,\n",
       " '##è­¬': 19414,\n",
       " 'æ¯': 3673,\n",
       " 'è¾–': 6785,\n",
       " '##èº': 18874,\n",
       " 'ä¹±': 744,\n",
       " 'éŸ¦': 7504,\n",
       " 'è¤»': 6196,\n",
       " 'september': 10024,\n",
       " '##É¡': 13369,\n",
       " '##æ¨½': 16631,\n",
       " 'published': 12821,\n",
       " 'cl': 12847,\n",
       " '##æ«š': 16660,\n",
       " 'è¯': 6414,\n",
       " 'æ¹Ÿ': 3962,\n",
       " '##ç¯·': 18133,\n",
       " '##ç—º': 17649,\n",
       " '##land': 8789,\n",
       " 'è’': 5887,\n",
       " 'eclipse': 11752,\n",
       " 'ç•¥': 4526,\n",
       " 'real': 10153,\n",
       " 'ç¿¦': 5430,\n",
       " 'åº†': 2412,\n",
       " 'dit': 13231,\n",
       " '##æ¢—': 16510,\n",
       " 'éƒœ': 6949,\n",
       " '##b': 8204,\n",
       " '##ç—¤': 17640,\n",
       " '##çŸ¥': 17818,\n",
       " 'æ’ˆ': 3051,\n",
       " 's': 161,\n",
       " '1934': 9823,\n",
       " 'é—¸': 7316,\n",
       " '##ten': 11598,\n",
       " '##ç¹†': 18305,\n",
       " '##è§': 19290,\n",
       " '##è©': 19327,\n",
       " '##éƒ': 20007,\n",
       " '##éŸ¦': 20561,\n",
       " '##nne': 12866,\n",
       " 'åˆ': 1151,\n",
       " 'è¾œ': 6790,\n",
       " '6': 127,\n",
       " '##Ë™': 13377,\n",
       " 'çš¿': 4654,\n",
       " 'æ±º': 3748,\n",
       " 'é”': 6888,\n",
       " 'æ': 2932,\n",
       " '##é¤Œ': 20679,\n",
       " 'ç³¾': 5144,\n",
       " 'å±†': 2234,\n",
       " '2l': 13191,\n",
       " '##æŸ»': 16454,\n",
       " 'è²Œ': 6505,\n",
       " '##ç—‰': 17627,\n",
       " '##è°Ÿ': 19524,\n",
       " '4d': 10571,\n",
       " 'æŒ': 2898,\n",
       " '##éŸµ': 20567,\n",
       " '##ã€”': 13661,\n",
       " '##io': 8652,\n",
       " '##èœ»': 19121,\n",
       " '##é­': 20851,\n",
       " 'éºµ': 7934,\n",
       " '##å‡': 14829,\n",
       " '##æ‡·': 15812,\n",
       " 'å¯': 1312,\n",
       " '##æ²§': 16828,\n",
       " 'å™±': 1694,\n",
       " 'æ§¿': 3554,\n",
       " '##é­”': 20852,\n",
       " 'æ¨¹': 3572,\n",
       " 'æ˜”': 3212,\n",
       " 'è°„': 6445,\n",
       " '##il': 8742,\n",
       " '##è² ': 19568,\n",
       " '1001': 11823,\n",
       " '##è‰°': 18737,\n",
       " 'äº²': 779,\n",
       " 'è¯µ': 6433,\n",
       " '##ç¥·': 17933,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 ç´¢å¼•è½¬æ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†è¯åºåˆ—è½¬æ¢ä¸ºidåºåˆ—\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['å¼±', 'å°', 'çš„', 'æˆ‘', 'ä¹Ÿ', 'æœ‰', 'å¤§', 'æ¢¦', 'æƒ³']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†idåºåˆ—è½¬æ¢ä¸ºtokenåºåˆ—\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å¼± å° çš„ æˆ‘ ä¹Ÿ æœ‰ å¤§ æ¢¦ æƒ³'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†tokenåºåˆ—è½¬æ¢ä¸ºstring\n",
    "str_sen = tokenizer.convert_tokens_to_string(tokens)\n",
    "str_sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### æ›´ä¾¿æ·çš„å®ç°æ–¹å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 10252, 8221, 106, 102]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºidåºåˆ—ï¼Œåˆç§°ä¹‹ä¸ºç¼–ç \n",
    "# ids = tokenizer.encode(sen, add_special_tokens=False)\n",
    "ids = tokenizer.encode(sen, add_special_tokens=True)  # é»˜è®¤ä¸ºTrue\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] å¼± å° çš„ æˆ‘ ä¹Ÿ æœ‰ å¤§ dreaming! [SEP]'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†idåºåˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œåˆç§°ä¹‹ä¸ºè§£ç \n",
    "str_sen = tokenizer.decode(ids, skip_special_tokens=False)  # é»˜è®¤ä¸ºFalse\n",
    "str_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5 å¡«å……ä¸æˆªæ–­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 102, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¡«å……\n",
    "ids = tokenizer.encode(sen, max_length=15,  padding=\"max_length\")\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] å¼± å° çš„ æˆ‘ ä¹Ÿ æœ‰ å¤§ æ¢¦ æƒ³ [SEP] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_sen = tokenizer.decode(ids, skip_special_tokens=False) # é»˜è®¤ä¸ºTrue\n",
    "str_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 102]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æˆªæ–­\n",
    "ids = tokenizer.encode(sen, max_length=5, truncation=True)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] å¼± å° çš„ [SEP]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_sen = tokenizer.decode(ids, skip_special_tokens=False) # é»˜è®¤ä¸ºTrue\n",
    "str_sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6 å…¶ä»–è¾“å…¥éƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 102, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(sen, padding=\"max_length\", max_length=15)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 102, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = [1 if idx != 0 else 0 for idx in ids]\n",
    "token_type_ids = [0] * len(ids)\n",
    "ids, attention_mask, token_type_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7 å¿«é€Ÿè°ƒç”¨æ–¹å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 102, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode_plus(sen, padding=\"max_length\", max_length=15)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 102, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sen, padding=\"max_length\", max_length=15)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8 å¤„ç†batchæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 102], [101, 3300, 3457, 2682, 6443, 6963, 749, 679, 6629, 102], [101, 6841, 6852, 3457, 2682, 4638, 2552, 8024, 3683, 3457, 2682, 3315, 6716, 8024, 3291, 1377, 6586, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens = [\"å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§æ¢¦æƒ³\",\n",
    "        \"æœ‰æ¢¦æƒ³è°éƒ½äº†ä¸èµ·\",\n",
    "        \"è¿½é€æ¢¦æƒ³çš„å¿ƒï¼Œæ¯”æ¢¦æƒ³æœ¬èº«ï¼Œæ›´å¯è´µ\"]\n",
    "res = tokenizer(sens)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªç¯å¤„ç†\n",
    "for i in range(1000):\n",
    "    tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = tokenizer([sen] * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast / Slow Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§Dreaming!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")  # é»˜è®¤æ˜¯Fastï¼Œæ²¡æœ‰Faståˆ™æ˜¯Slow\n",
    "fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\", use_fast=False)\n",
    "slow_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 469 ms\n",
      "Wall time: 551 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªç¯å¤„ç†\n",
    "for i in range(10000):\n",
    "    fast_tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.47 s\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªç¯å¤„ç†\n",
    "for i in range(10000):\n",
    "    slow_tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 344 ms\n",
      "Wall time: 140 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = fast_tokenizer([sen] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.27 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = slow_tokenizer([sen] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 10252, 8221, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 12), (12, 15), (15, 16), (0, 0)]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = fast_tokenizer(sen, return_offsets_mapping=True)  # å¤šäº†offset_mappingå‚æ•°\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "return_offset_mapping is not available when using Python tokenizers. To use this feature, change your tokenizer to one deriving from transformers.PreTrainedTokenizerFast. More information on available tokenizers at https://github.com/huggingface/transformers/pull/2674",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mslow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# æŠ¥é”™\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2945\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2943\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2944\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2945\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[0;32m   2946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3053\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   3032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   3033\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   3034\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3050\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3051\u001b[0m     )\n\u001b[0;32m   3052\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   3054\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   3055\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   3056\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   3057\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3058\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   3059\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   3060\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   3061\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   3062\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3063\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   3064\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   3065\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   3066\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   3067\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   3068\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   3069\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   3070\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3071\u001b[0m         split_special_tokens\u001b[38;5;241m=\u001b[39msplit_special_tokens,\n\u001b[0;32m   3072\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3073\u001b[0m     )\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3127\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3117\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3118\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3119\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3120\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3124\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3125\u001b[0m )\n\u001b[1;32m-> 3127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[0;32m   3128\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   3129\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   3130\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   3131\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   3132\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   3133\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   3134\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   3135\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   3136\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3137\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   3138\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   3139\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   3140\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   3141\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   3142\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   3143\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   3144\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3145\u001b[0m     split_special_tokens\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_special_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_special_tokens),\n\u001b[0;32m   3146\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3147\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\tokenization_utils.py:780\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    774\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    775\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not valid. Should be a string, a list/tuple of strings or a list/tuple of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    776\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m integers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    777\u001b[0m             )\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m--> 780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    782\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.PreTrainedTokenizerFast. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore information on available tokenizers at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    786\u001b[0m     )\n\u001b[0;32m    788\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text)\n\u001b[0;32m    789\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: return_offset_mapping is not available when using Python tokenizers. To use this feature, change your tokenizer to one deriving from transformers.PreTrainedTokenizerFast. More information on available tokenizers at https://github.com/huggingface/transformers/pull/2674"
     ]
    }
   ],
   "source": [
    "inputs = slow_tokenizer(sen, return_offsets_mapping=True)  # æŠ¥é”™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç‰¹æ®ŠTokenizerçš„åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkyworkTokenizer(name_or_path='Skywork/Skywork-13B-base', vocab_size=65519, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ–°ç‰ˆæœ¬çš„transformersï¼ˆ>4.34ï¼‰ï¼ŒåŠ è½½ THUDM/chatglm ä¼šæŠ¥é”™ï¼Œå› æ­¤è¿™é‡Œæ›¿æ¢ä¸ºäº†å¤©å®«çš„æ¨¡å‹\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Skywork/Skywork-13B-base\", trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)  # æ—§ç‰ˆæœ¬\n",
    "tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('skywork_tokenizer\\\\tokenizer_config.json',\n",
       " 'skywork_tokenizer\\\\special_tokens_map.json',\n",
       " 'skywork_tokenizer\\\\tokenizer.model',\n",
       " 'skywork_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"skywork_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"skywork_tokenizer\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§Dreaming!'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 29871, 55215, 30210, 30672, 30953, 30417, 30257, 29928, 1633, 292, 29991], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
